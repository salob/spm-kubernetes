{"componentChunkName":"component---src-pages-supporting-infrastructure-batch-mdx","path":"/supporting-infrastructure/batch/","result":{"pageContext":{"frontmatter":{"title":"SPM batch processing on IKS","description":"SPM batch processing on IKS"},"relativePagePath":"/supporting-infrastructure/batch.mdx","titleType":"page","MdxNode":{"id":"8b28da33-d385-58d3-aa7c-3b0aaf05362a","children":[],"parent":"7f5b3f0e-a17c-5ba1-b613-5983229eccac","internal":{"content":"---\ntitle: SPM batch processing on IKS\ndescription: SPM batch processing on IKS\n---\n\n## How batch streaming is deployed in IBM® Cloud™ Kubernetes Services (IKS)\n\nSPM on Kubernetes supports a different model for batch processing in IKS, where, as outlined earlier, SPM batch processing can be built and deployed into its own pod.\nBy running SPM batch processing in its own pod, the pod can leverage the benefits of flexibility, elasticity, efficiency and the strategic value offered by cloud native architecture.\n\n### What is batch streaming?\n\nThe batch streaming infrastructure provides a straightforward mechanism to implement a batch process so that it can be run in parallel (streams) across multiple pods.\nFor example, if we wanted to issue payments, the chunker identifies all the cases to be paid and the stream would process a case and issue the payments that are due.\n\n<InlineNotification>\n\n**Note:** For more information, see [Batch Streaming Architecture](https://www.ibm.com/support/knowledgecenter/SS8S5A_7.0.10/com.ibm.curam.content.doc/BatchPerformanceMechanisms/c_BATCHPER_Architecture1AdditionalInformation1.html)\n\n</InlineNotification>\n\n### Setting up Batch Streaming yaml files\n\nOutlined below is an example for the steps required to set up Batch Streaming.\nThis example uses the bulk reassessment of food assistance case types.\n\nThe first stage is to set up a new yaml file for the streaming and chunking batch processing.\n\n<InlineNotification>\n\n**Note:** No SPM default installation settings were changed.\n\n</InlineNotification>\n\n```shell\nexport NAMESPACE=\nexport releasename=\nkubectl create job --from=cronjob/$releasename-batch -n $NAMESPACE -o yaml --dry-run testjob > yaml_chart_name.yaml\n```\n\n<InlineNotification>\n\n**Note:** where\n\n* NAMESPACE is the namespace where you want to run the batch processing\n* releaseName is the name of the release you are using\n* yaml_chart_name is the name of the chart you are creating\n You should create a new chart for each process, for example stream_foodassistance, and chunker_foodassistance.\n\n</InlineNotification>\n\nA corresponding `yaml` file is created.\nOpen the yaml file in an editor e.g\n\n```shell\nvi `chunker_foodassistance.yaml`\n```\n\nAdd the following lines to the yaml file after the `containers` section:\n\n<Tabs>\n\n<Tab label=\"Chunker\">\n<Row>\n<Column>\n\n```yaml\nspec:\n  backoffLimit: 5\n  template:\n    metadata:\n      creationTimestamp: null\n    spec:\n      containers:\n      - command:\n          - build.sh\n          - runbatch\n        args:\n          - -Dcuram.jmx.output_statistics_timer_enabled=true\n          - -Dcuram.jmx.output_statistics_timer_folder=/tmp\n          - -Dcuram.jmx.output_statistics_timer_period=60000\n          - -Dbatch.program=curam.core.sl.infrastructure.assessment.intf.CREOLEBulkCaseChunkReassessmentByProduct.process\n          - -Dbatch.parameters=\"productID=4200\"\n        env:\n          - name: ANT_OPTS\n            value: -Xgcpolicy:gencon -Xverbosegclog:/tmp/GCLogs_chunker.log\n        image: ......\n\n```\n\n</Column>\n</Row>\n</Tab>\n\n<Tab label=\"Stream\">\n<Row>\n<Column>\n\n```yaml\nspec:\n  backoffLimit: 5\n  template:\n    metadata:\n      creationTimestamp: null\n    spec:\n      containers:\n      - command:\n          - build.sh\n          - runbatch\n        args:\n          - -Dcuram.jmx.output_statistics_timer_enabled=true\n          - -Dcuram.jmx.output_statistics_timer_folder=/tmp\n          - -Dcuram.jmx.output_statistics_timer_period=60000\n          - -Dbatch.program=curam.core.sl.infrastructure.assessment.intf.CREOLEBulkCaseChunkReassessmentStream.process\n        env:\n          - name: ANT_OPTS\n            value: -Xgcpolicy:gencon -Xverbosegclog:/tmp/GCLogs_stream.log\n        image: ......\n\n```\n\n</Column>\n</Row>\n</Tab>\n\n</Tabs>\n\nYou should now have a yaml file for a chunker and streamer for bulk reassessment of food assistance case types.\n\n### Running batch streaming yaml files\n\nTo orchestrate the batch process, run the following command and repeat for the chunker and streamer.\n\n```shell\nkubectl create -f yaml_chart_name.yaml -n $NAMESPACE\n```\n\n![spm batch on kubernetes](../../images/spm_batch_processing_on_kubernetes.png)\n<Caption>\n\n*Figure 1:* SPM batch processing on kubernetes\n\n</Caption>\n\n<InlineNotification>\n\n**Note:** where\n\n* NAMESPACE is the namespace where you want to run the batch processing.\n* yaml_chart_name is the name of the chart you are creating.\n\n</InlineNotification>\n\n### Post batch processing\n\nThe batch pods that are created for batch streaming are on demand.\n\nWhen the batch processes finish, the pods remain and are not shut down.\nTherefore you should destroy the related pods to free resources in the IKS cluster\n","type":"Mdx","contentDigest":"c72c53753f2f457f8c2d523c9788bc11","counter":169,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"SPM batch processing on IKS","description":"SPM batch processing on IKS"},"exports":{},"rawBody":"---\ntitle: SPM batch processing on IKS\ndescription: SPM batch processing on IKS\n---\n\n## How batch streaming is deployed in IBM® Cloud™ Kubernetes Services (IKS)\n\nSPM on Kubernetes supports a different model for batch processing in IKS, where, as outlined earlier, SPM batch processing can be built and deployed into its own pod.\nBy running SPM batch processing in its own pod, the pod can leverage the benefits of flexibility, elasticity, efficiency and the strategic value offered by cloud native architecture.\n\n### What is batch streaming?\n\nThe batch streaming infrastructure provides a straightforward mechanism to implement a batch process so that it can be run in parallel (streams) across multiple pods.\nFor example, if we wanted to issue payments, the chunker identifies all the cases to be paid and the stream would process a case and issue the payments that are due.\n\n<InlineNotification>\n\n**Note:** For more information, see [Batch Streaming Architecture](https://www.ibm.com/support/knowledgecenter/SS8S5A_7.0.10/com.ibm.curam.content.doc/BatchPerformanceMechanisms/c_BATCHPER_Architecture1AdditionalInformation1.html)\n\n</InlineNotification>\n\n### Setting up Batch Streaming yaml files\n\nOutlined below is an example for the steps required to set up Batch Streaming.\nThis example uses the bulk reassessment of food assistance case types.\n\nThe first stage is to set up a new yaml file for the streaming and chunking batch processing.\n\n<InlineNotification>\n\n**Note:** No SPM default installation settings were changed.\n\n</InlineNotification>\n\n```shell\nexport NAMESPACE=\nexport releasename=\nkubectl create job --from=cronjob/$releasename-batch -n $NAMESPACE -o yaml --dry-run testjob > yaml_chart_name.yaml\n```\n\n<InlineNotification>\n\n**Note:** where\n\n* NAMESPACE is the namespace where you want to run the batch processing\n* releaseName is the name of the release you are using\n* yaml_chart_name is the name of the chart you are creating\n You should create a new chart for each process, for example stream_foodassistance, and chunker_foodassistance.\n\n</InlineNotification>\n\nA corresponding `yaml` file is created.\nOpen the yaml file in an editor e.g\n\n```shell\nvi `chunker_foodassistance.yaml`\n```\n\nAdd the following lines to the yaml file after the `containers` section:\n\n<Tabs>\n\n<Tab label=\"Chunker\">\n<Row>\n<Column>\n\n```yaml\nspec:\n  backoffLimit: 5\n  template:\n    metadata:\n      creationTimestamp: null\n    spec:\n      containers:\n      - command:\n          - build.sh\n          - runbatch\n        args:\n          - -Dcuram.jmx.output_statistics_timer_enabled=true\n          - -Dcuram.jmx.output_statistics_timer_folder=/tmp\n          - -Dcuram.jmx.output_statistics_timer_period=60000\n          - -Dbatch.program=curam.core.sl.infrastructure.assessment.intf.CREOLEBulkCaseChunkReassessmentByProduct.process\n          - -Dbatch.parameters=\"productID=4200\"\n        env:\n          - name: ANT_OPTS\n            value: -Xgcpolicy:gencon -Xverbosegclog:/tmp/GCLogs_chunker.log\n        image: ......\n\n```\n\n</Column>\n</Row>\n</Tab>\n\n<Tab label=\"Stream\">\n<Row>\n<Column>\n\n```yaml\nspec:\n  backoffLimit: 5\n  template:\n    metadata:\n      creationTimestamp: null\n    spec:\n      containers:\n      - command:\n          - build.sh\n          - runbatch\n        args:\n          - -Dcuram.jmx.output_statistics_timer_enabled=true\n          - -Dcuram.jmx.output_statistics_timer_folder=/tmp\n          - -Dcuram.jmx.output_statistics_timer_period=60000\n          - -Dbatch.program=curam.core.sl.infrastructure.assessment.intf.CREOLEBulkCaseChunkReassessmentStream.process\n        env:\n          - name: ANT_OPTS\n            value: -Xgcpolicy:gencon -Xverbosegclog:/tmp/GCLogs_stream.log\n        image: ......\n\n```\n\n</Column>\n</Row>\n</Tab>\n\n</Tabs>\n\nYou should now have a yaml file for a chunker and streamer for bulk reassessment of food assistance case types.\n\n### Running batch streaming yaml files\n\nTo orchestrate the batch process, run the following command and repeat for the chunker and streamer.\n\n```shell\nkubectl create -f yaml_chart_name.yaml -n $NAMESPACE\n```\n\n![spm batch on kubernetes](../../images/spm_batch_processing_on_kubernetes.png)\n<Caption>\n\n*Figure 1:* SPM batch processing on kubernetes\n\n</Caption>\n\n<InlineNotification>\n\n**Note:** where\n\n* NAMESPACE is the namespace where you want to run the batch processing.\n* yaml_chart_name is the name of the chart you are creating.\n\n</InlineNotification>\n\n### Post batch processing\n\nThe batch pods that are created for batch streaming are on demand.\n\nWhen the batch processes finish, the pods remain and are not shut down.\nTherefore you should destroy the related pods to free resources in the IKS cluster\n","fileAbsolutePath":"/home/travis/build/IBM/spm-kubernetes/src/pages/supporting-infrastructure/batch.mdx"}}}}