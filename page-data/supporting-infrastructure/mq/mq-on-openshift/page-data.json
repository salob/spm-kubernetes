{"componentChunkName":"component---src-pages-supporting-infrastructure-mq-mq-on-openshift-mdx","path":"/supporting-infrastructure/mq/mq-on-openshift/","result":{"pageContext":{"frontmatter":{"title":"MQ on OpenShift","description":"MQ on OpenShift","tabs":["MQ Overview","MQ on IKS","MQ on OpenShift"]},"relativePagePath":"/supporting-infrastructure/mq/mq-on-openshift.mdx","titleType":"page","MdxNode":{"id":"401d9077-f988-5c8d-b08b-e96d838c18c5","children":[],"parent":"5c85bf10-6d4f-51ea-84cb-6a47f176386c","internal":{"content":"---\ntitle: MQ on OpenShift\ndescription: MQ on OpenShift\ntabs: ['MQ Overview','MQ on IKS', 'MQ on OpenShift']\n---\n\n## Stateful Sets\n\nIf a highly available MQ cluster is desired, a **Stateful Set** can be used. The stateful set used for SPM contains two identical\npods, one active pod and one standby pod. If the active pod goes down, the standby pod is moved into the active role and a new pod is rescheduled in standby mode.\nThis occurs seamlessly, with persistent storage allowing for minimal downtime. The Stateful Set used in SPM requires several values that must be configured prior to\ndeployment. These values are those located under the MQ `multiInstance` section within the relevant values file. There, NFS or Ceph can be chosen as the desired\nmulti-instance delivery method.\n\n* **NFS** - In order to deploy with NFS, an NFS server and NFS folder must be available and configured; the supplementalGroups may need to be provided depending on the NFS server security setup.\n* **Ceph** - In order to deploy with Ceph, the desired Storage Class must be provided.\n\n## Persistent Volumes & Persistent Volume Claims\n\nA **PersistentVolume** (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes.\nIt is a resource in the cluster just like a node is a cluster resource. A **PersistentVolumeClaim** (PVC) is a request for storage by a user. It is similar to\na Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific\nsize and access modes.\n\nWhen using NFS as the desired multi-instance method, the PV and PVCs must be configured by the user. Within the PVs, the NFS IP and NFS folder must be provided.\nIn the PV, a `claimRef` can be defined in order to ensure that the correct PVC matches with the correct PV. The templates provided also contain labels, which can\nalso be used to ensure correct coupling.\n\nIf using Ceph, the PVs are dynamically configured. Therefore, no further configuration is required.\n","type":"Mdx","contentDigest":"f848fa391578c9a13672b9aa5440a7d7","counter":181,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"MQ on OpenShift","description":"MQ on OpenShift","tabs":["MQ Overview","MQ on IKS","MQ on OpenShift"]},"exports":{},"rawBody":"---\ntitle: MQ on OpenShift\ndescription: MQ on OpenShift\ntabs: ['MQ Overview','MQ on IKS', 'MQ on OpenShift']\n---\n\n## Stateful Sets\n\nIf a highly available MQ cluster is desired, a **Stateful Set** can be used. The stateful set used for SPM contains two identical\npods, one active pod and one standby pod. If the active pod goes down, the standby pod is moved into the active role and a new pod is rescheduled in standby mode.\nThis occurs seamlessly, with persistent storage allowing for minimal downtime. The Stateful Set used in SPM requires several values that must be configured prior to\ndeployment. These values are those located under the MQ `multiInstance` section within the relevant values file. There, NFS or Ceph can be chosen as the desired\nmulti-instance delivery method.\n\n* **NFS** - In order to deploy with NFS, an NFS server and NFS folder must be available and configured; the supplementalGroups may need to be provided depending on the NFS server security setup.\n* **Ceph** - In order to deploy with Ceph, the desired Storage Class must be provided.\n\n## Persistent Volumes & Persistent Volume Claims\n\nA **PersistentVolume** (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes.\nIt is a resource in the cluster just like a node is a cluster resource. A **PersistentVolumeClaim** (PVC) is a request for storage by a user. It is similar to\na Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific\nsize and access modes.\n\nWhen using NFS as the desired multi-instance method, the PV and PVCs must be configured by the user. Within the PVs, the NFS IP and NFS folder must be provided.\nIn the PV, a `claimRef` can be defined in order to ensure that the correct PVC matches with the correct PV. The templates provided also contain labels, which can\nalso be used to ensure correct coupling.\n\nIf using Ceph, the PVs are dynamically configured. Therefore, no further configuration is required.\n","fileAbsolutePath":"/home/travis/build/IBM/spm-kubernetes/src/pages/supporting-infrastructure/mq/mq-on-openshift.mdx"}}}}